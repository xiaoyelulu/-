{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "深入浅出pytorch第二讲",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#一个神经网络的典型训练过程如下：\n",
        "\n",
        "1. 定义包含一些可学习参数(或者叫权重）的神经网络\n",
        "\n",
        "2. 在输入数据集上迭代\n",
        "\n",
        "3. 通过网络处理输入\n",
        "\n",
        "4. 计算 loss (输出和正确答案的距离）\n",
        "\n",
        "5. 将梯度反向传播给网络的参数\n",
        "\n",
        "6. 更新网络的权重，一般使用一个简单的规则：$weight = weight - learning\\_rate * gradient$"
      ],
      "metadata": {
        "id": "ugU-1T-yx6L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "I17b-sP0gUre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "batch_size=256\n",
        "num_workers=4\n",
        "lr=1e-4\n",
        "epochs=20"
      ],
      "metadata": {
        "id": "9auMvilGFlsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据读入\n",
        "PyTorch数据读入是通过Dataset+DataLoader的方式完成的，Dataset定义好数据的格式和数据变换形式，DataLoader用iterative的方式不断读入批次数据。"
      ],
      "metadata": {
        "id": "yqdms8nTJApo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#首先设置数据变换\n",
        "from torchvision import transforms\n",
        "image_size=28\n",
        "data_transform=transforms.Compose([\n",
        "    transforms.ToPILImage(),#这一步取决于后续的数据读取方式，如果使用的时内置数据集则不需要\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor()\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "DnO3jdWTGcrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 读取方式一：使用torchvision自带数据集\n",
        "from torchvision import datasets\n",
        "train_data1=datasets.FashionMNIST(root='./',train=True,download=True,transform=data_transform)\n",
        "test_data1=datasets.FashionMNIST(root='./',train=False,download=True,transform=data_transform)"
      ],
      "metadata": {
        "id": "_rZPa0FuJdit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：\n",
        "\n",
        "-  \\_\\_init__: 用于向类中传入外部参数，同时定义样本集\n",
        "\n",
        "-  \\_\\_getitem__: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据\n",
        "\n",
        "- \\_\\_len__: 用于返回数据集的样本数"
      ],
      "metadata": {
        "id": "noPTRae8N_O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##读取方式二：读入csv格式的数据，自行构建dataset类\n",
        "#csv数据下载地址：https://www.kaggle.com/datasets/xiaoqingjiang/fashionmnist?resource=download\n",
        "class FMDataset(Dataset):\n",
        "  def __init__(self,df,transform=None):\n",
        "    self.df=df\n",
        "    self.transform=transform\n",
        "    self.images=df.iloc[:,1:].values.astype(np.uint8)\n",
        "    self.labels=df.iloc[:,0].values\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  def __getitem__(self,idx):\n",
        "    image=self.images[idx].reshape(28,28,1)\n",
        "    label=int(self.labels[idx])\n",
        "    if self.transform is not None:\n",
        "      image=self.transform(image)\n",
        "    else:\n",
        "      image=torch.tensor(image/255.,dtype=torch.float)\n",
        "    label=torch.tensor(label,dtype=torch.long)\n",
        "    return image,label\n",
        "\n",
        "train_df=pd.read_csv(\"/content/drive/MyDrive/archive/fashion-mnist_train.csv\")\n",
        "test_df=pd.read_csv(\"/content/drive/MyDrive/archive/fashion-mnist_test.csv\")\n",
        "train_data=FMDataset(train_df,data_transform)\n",
        "test_data=FMDataset(test_df,data_transform)\n"
      ],
      "metadata": {
        "id": "U3U8ClGsKorJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31NtzHvWRqCE",
        "outputId": "1c81c3d0-9a43-4c62-c815-1749df347a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里另外给出一个例子，其中图片存放在一个文件夹，另外有一个csv文件给出了图片名称对应的标签。这种情况下需要自己来定义Dataset类："
      ],
      "metadata": {
        "id": "eH8HUBb8Qsnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dir, info_csv, image_list, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir: path to image directory.\n",
        "            info_csv: path to the csv file containing image indexes\n",
        "                with corresponding labels.\n",
        "            image_list: path to the txt file contains image names to training/validation set\n",
        "            transform: optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        label_info = pd.read_csv(info_csv)\n",
        "        image_file = open(image_list).readlines()\n",
        "        self.data_dir = data_dir\n",
        "        self.image_file = image_file\n",
        "        self.label_info = label_info\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index: the index of item\n",
        "        Returns:\n",
        "            image and its labels\n",
        "        \"\"\"\n",
        "        image_name = self.image_file[index].strip('\\n')\n",
        "        raw_label = self.label_info.loc[self.label_info['Image_index'] == image_name]\n",
        "        label = raw_label.iloc[:,0]\n",
        "        image_name = os.path.join(self.data_dir, image_name)\n",
        "        image = Image.open(image_name).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file)"
      ],
      "metadata": {
        "id": "t0Thm4oKQoIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在构建训练和测试数据集完成后，需要定义Dataloader类，以便在训练和测试时加载数据。\n",
        "\n",
        "其中:\n",
        "\n",
        "- batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数\n",
        "\n",
        "- num_workers：有多少个进程用于读取数据\n",
        "\n",
        "- shuffle：是否将读入的数据打乱\n",
        "\n",
        "- drop_last：对于样本最后一部分没有达到批次数的样本，使其不再参与训练"
      ],
      "metadata": {
        "id": "iopz90GvSFHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=num_workers,drop_last=True)\n",
        "test_loader=DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=num_workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69Db6sF5R9Gy",
        "outputId": "2b0dd894-4ea4-43af-b37e-1b5817a43d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgoq7adVFdTe",
        "outputId": "54e2da00-21cd-41fb-8c11-7447407b446a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里可以看一下我们的加载的数据。PyTorch中的DataLoader的读取可以使用next和iter来完成"
      ],
      "metadata": {
        "id": "jLpvKPodoroI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "images, labels=next(iter(train_loader))\n",
        "print(images.shape,labels.shape)\n",
        "plt.imshow(images[0][0],cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "mdbRf2hAmRw5",
        "outputId": "55f516b4-45ba-4c94-842c-f702fb8eeff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8a8cd97b10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型构建\n",
        "PyTorch中神经网络构造一般是基于 Module 类的模型来完成的，它让模型构造更加灵活。  \n",
        "\n",
        "Module 类是 nn 模块里提供的一个模型构造类，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型。重载了 Module 类的\\_\\_init__函数和\\_\\_forward__ 函数"
      ],
      "metadata": {
        "id": "8ciFc8n5r13M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv=nn.Sequential(\n",
        "        nn.Conv2d(1,32,5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,stride=2),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Conv2d(32,64,5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,stride=2),\n",
        "        nn.Dropout(0.3)\n",
        "\n",
        "    )\n",
        "    self.fc=nn.Sequential(\n",
        "        nn.Linear(64*4*4,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.conv(x)\n",
        "    x=x.view(-1,64*4*4)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "model=Net()\n",
        "model=model.cuda()\n",
        "#model=nn.DataParallel(model).cuda()#多卡训练时的写法"
      ],
      "metadata": {
        "id": "T6O_GAnTr1P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一个模型的可学习参数可以通过net.parameters()返回"
      ],
      "metadata": {
        "id": "V1fD5lfOyxd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1的权重"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_RV0fojxGVZ",
        "outputId": "462ddce8-bced-4e70-a8dc-1cb1b7635bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "torch.Size([32, 1, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 损失函数"
      ],
      "metadata": {
        "id": "CUZKkS2sxG_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()          # ?nn.Conv2d  #查找疑问函数"
      ],
      "metadata": {
        "id": "d9ZH6DnLmTZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 优化器\n",
        "\n",
        "- load_state_dict() ：加载状态参数字典，可以用来进行模型的断点续训练，继续上次的参数进行训练\n",
        "- state_dict()：获取优化器当前状态信息字典"
      ],
      "metadata": {
        "id": "etvPY510GPYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "liaGeDLCuQ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型训练与预测"
      ],
      "metadata": {
        "id": "zsEeX2SniHOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  #for i,(data,label) in enumerate(train_loader):          #每一个batch都需要做一些操作\n",
        "  for data,label in train_loader:\n",
        "    data,label=data.cuda(),label.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(data)\n",
        "    loss=criterion(output,label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss+=loss.item()*data.size(0)\n",
        "  train_loss=train_loss/len(train_loader.dataset)\n",
        "  print('Epoch:{} \\t Training Loss:{:.6f}'.format(epoch,train_loss))\n"
      ],
      "metadata": {
        "id": "E3UjduMNGkQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(epoch):\n",
        "  model.eval()\n",
        "  val_loss=0\n",
        "  gt_labels=[]\n",
        "  pred_labels=[]\n",
        "  with torch.no_grad():\n",
        "    for data,label in test_loader:\n",
        "      data,label=data.cuda(),label.cuda()\n",
        "      output=model(data)\n",
        "      preds=torch.argmax(output,1)\n",
        "      gt_labels.append(label.cpu().data.numpy())\n",
        "      pred_labels.append(preds.cpu().data.numpy())\n",
        "      loss=criterion(output,label)\n",
        "      val_loss+=loss.item()*data.size(0)\n",
        "  val_loss=val_loss/len(test_loader.dataset)\n",
        "  gt_labels,pred_labels=np.concatenate(gt_labels),np.concatenate(pred_labels)\n",
        "  acc=np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
        "  print('Epoch:{}\\tValidation Loss:{:.6f},Accuracy:{:6f}'.format(epoch,val_loss,acc))"
      ],
      "metadata": {
        "id": "Q65_hKkjjl-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs+1):\n",
        "  train(epoch)\n",
        "  val(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kuXEeWrOnRGh",
        "outputId": "1dc84760-ecd9-4c52-f9f2-5da0f5f098f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 \t Training Loss:0.232848\n",
            "Epoch:1\tValidation Loss:0.218499,Accuracy:0.916100\n",
            "Epoch:2 \t Training Loss:0.223912\n",
            "Epoch:2\tValidation Loss:0.212212,Accuracy:0.919200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0ba6005121ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-40cbcaed6586>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#for i,(data,label) in enumerate(train_loader):          #每一个batch都需要做一些操作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info=!nvidia-smi -i 0\n",
        "gpu_info='\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TIXuDBpq9wR",
        "outputId": "8085c1a9-cca6-4c99-ed6b-fc6b6b6b34d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 30 17:01:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    35W /  70W |   1356MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 补充 优化器实际操作\n"
      ],
      "metadata": {
        "id": "YJHBBUSBs6Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# 设置权重，服从正态分布  --> 2 x 2\n",
        "weight = torch.randn((2, 2), requires_grad=True)\n",
        "# 设置梯度为全1矩阵  --> 2 x 2\n",
        "weight.grad = torch.ones((2, 2))\n",
        "# 输出现有的weight和data\n",
        "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
        "print(\"The grad of weight before step:\\n{}\".format(weight.grad))\n",
        "# 实例化优化器\n",
        "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
        "# 进行一步操作\n",
        "optimizer.step()\n",
        "# 查看进行一步后的值，梯度\n",
        "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
        "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
        "# 权重清零\n",
        "optimizer.zero_grad()\n",
        "# 检验权重是否为0\n",
        "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))\n",
        "# 输出参数\n",
        "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
        "# 查看参数位置，optimizer和weight的位置一样，我觉得这里可以参考Python是基于值管理\n",
        "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
        "# 添加参数：weight2\n",
        "weight2 = torch.randn((3, 3), requires_grad=True)\n",
        "optimizer.add_param_group({\"params\": weight2, 'lr': 0.0001, 'nesterov': True})\n",
        "# 查看现有的参数\n",
        "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
        "# 查看当前状态信息\n",
        "opt_state_dict = optimizer.state_dict()\n",
        "print(\"state_dict before step:\\n\", opt_state_dict)\n",
        "# 进行5次step操作\n",
        "for _ in range(50):\n",
        "    optimizer.step()\n",
        "# 输出现有状态信息\n",
        "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
        "# 保存参数信息\n",
        "torch.save(optimizer.state_dict(),os.path.join(r\"/content/sample_data\", \"optimizer_state_dict.pkl\"))\n",
        "print(\"----------done-----------\")\n",
        "# 加载参数信息\n",
        "state_dict = torch.load(r\"/content/sample_data/optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
        "optimizer.load_state_dict(state_dict)\n",
        "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
        "# 输出最后属性信息\n",
        "print(\"\\n{}\".format(optimizer.defaults))\n",
        "print(\"\\n{}\".format(optimizer.state))\n",
        "print(\"\\n{}\".format(optimizer.param_groups))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Wp5EBTsdzK",
        "outputId": "1b27ab1d-8afd-41c9-acfc-ca4d5df3e9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data of weight before step:\n",
            "tensor([[ 0.5669, -1.4336],\n",
            "        [-0.0478,  0.0569]])\n",
            "The grad of weight before step:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "The data of weight after step:\n",
            "tensor([[ 0.4669, -1.5336],\n",
            "        [-0.1478, -0.0431]])\n",
            "The grad of weight after step:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "The grad of weight after optimizer.zero_grad():\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "optimizer.params_group is \n",
            "[{'params': [tensor([[ 0.4669, -1.5336],\n",
            "        [-0.1478, -0.0431]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}]\n",
            "weight in optimizer:140229849734320\n",
            "weight in weight:140229849734320\n",
            "\n",
            "optimizer.param_groups is\n",
            "[{'params': [tensor([[ 0.4669, -1.5336],\n",
            "        [-0.1478, -0.0431]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}, {'params': [tensor([[-0.6185, -0.4379, -0.1994],\n",
            "        [ 1.4959,  0.1005, -0.0620],\n",
            "        [-0.3811, -0.4716,  0.6279]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None}]\n",
            "state_dict before step:\n",
            " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
            "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'params': [1]}]}\n",
            "state_dict after step:\n",
            " {'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
            "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'params': [1]}]}\n",
            "----------done-----------\n",
            "load state_dict successfully\n",
            "{'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
            "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'params': [1]}]}\n",
            "\n",
            "{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}\n",
            "\n",
            "defaultdict(<class 'dict'>, {tensor([[-0.4285, -2.4290],\n",
            "        [-1.0432, -0.9385]], requires_grad=True): {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
            "        [0.0052, 0.0052]])}})\n",
            "\n",
            "[{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [tensor([[-0.4285, -2.4290],\n",
            "        [-1.0432, -0.9385]], requires_grad=True)]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'params': [tensor([[-0.6185, -0.4379, -0.1994],\n",
            "        [ 1.4959,  0.1005, -0.0620],\n",
            "        [-0.3811, -0.4716,  0.6279]], requires_grad=True)]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "输出结果\n",
        "\n",
        "进行更新前的数据，梯度\n",
        "\n",
        "The data of weight before step:\n",
        "tensor([[-0.3077, -0.1808],\n",
        "        [-0.7462, -1.5556]])\n",
        "The grad of weight before step:\n",
        "tensor([[1., 1.],\n",
        "        [1., 1.]])\n",
        "\n",
        "进行更新后的数据，梯度\n",
        "\n",
        "The data of weight after step:\n",
        "tensor([[-0.4077, -0.2808],\n",
        "        [-0.8462, -1.6556]])\n",
        "The grad of weight after step:\n",
        "tensor([[1., 1.],\n",
        "        [1., 1.]])\n",
        "\n",
        "进行梯度清零的梯度\n",
        "\n",
        "The grad of weight after optimizer.zero_grad():\n",
        "tensor([[0., 0.],\n",
        "        [0., 0.]])\n",
        "\n",
        "输出信息\n",
        "\n",
        "optimizer.params_group is \n",
        "[{'params': [tensor([[-0.4077, -0.2808],\n",
        "        [-0.8462, -1.6556]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
        "\n",
        "\n",
        "证明了优化器的和weight的储存是在一个地方，Python基于值管理\n",
        "weight in optimizer:1841923407424\n",
        "weight in weight:1841923407424\n",
        "    \n",
        "输出参数\n",
        "\n",
        "optimizer.param_groups is\n",
        "[{'params': [tensor([[-0.4077, -0.2808],\n",
        "        [-0.8462, -1.6556]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}, {'params': [tensor([[ 0.4539, -2.1901, -0.6662],\n",
        "        [ 0.6630, -1.5178, -0.8708],\n",
        "        [-2.0222,  1.4573,  0.8657]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0}]\n",
        "\n",
        "进行更新前的参数查看，用state_dict\n",
        "\n",
        "state_dict before step:\n",
        " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
        "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
        "\n",
        "进行更新后的参数查看，用state_dict\n",
        "\n",
        "state_dict after step:\n",
        " {'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
        "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
        "\n",
        "存储信息完毕\n",
        "\n",
        "----------done-----------\n",
        "\n",
        "加载参数信息成功\n",
        "\n",
        "load state_dict successfully\n",
        "\n",
        "加载参数信息\n",
        "\n",
        "{'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
        "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
        "\n",
        "defaults的属性输出\n",
        "\n",
        "{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}\n",
        "\n",
        "state属性输出\n",
        "\n",
        "defaultdict(<class 'dict'>, {tensor([[-1.3031, -1.1761],\n",
        "        [-1.7415, -2.5510]], requires_grad=True): {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
        "        [0.0052, 0.0052]])}})\n",
        "\n",
        "param_groups属性输出\n",
        "\n",
        "[{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [tensor([[-1.3031, -1.1761],\n",
        "        [-1.7415, -2.5510]], requires_grad=True)]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [tensor([[ 0.4539, -2.1901, -0.6662],\n",
        "        [ 0.6630, -1.5178, -0.8708],\n",
        "        [-2.0222,  1.4573,  0.8657]], requires_grad=True)]}]\n"
      ],
      "metadata": {
        "id": "3R-xSynYtMAd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59U1IU5wtGi6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}